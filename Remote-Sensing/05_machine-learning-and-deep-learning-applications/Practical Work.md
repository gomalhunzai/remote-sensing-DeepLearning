---
publishable: false
tags: []
date_updated: 2025-07-22
author: Generated by AI
---

# Exercises (remote sensing undergradute) â€“ Machine Learning and Deep Learning Applications
> Here are 10 practical exercises to apply the concepts from the chapter "Machine Learning and Deep Learning Applications" and prepare for the assessment. They are specifically designed for remote sensing undergradute.

---

> [!question]
> ### Exercise 1: Land Cover Classification with SVM
> You are provided with a Sentinel-2 multispectral image cutout of a mixed rural-urban area and a shapefile containing training polygons for 5 distinct land cover classes (e.g., water, forest, urban, agriculture, bare soil).
>
> Your task is to:
> 1.  Extract pixel values for the training polygons.
> 2.  Train a `==Support Vector Machine (SVM)==` classifier using the extracted data.
> 3.  Apply the trained model to classify the entire image.
> 4.  Perform an `==accuracy assessment==` using a reserved portion of your data and present the results in a `==confusion matrix==`.
>
> > [!TIP] Hint
> > The choice of kernel (e.g., linear, RBF) and the tuning of hyperparameters like `C` and `gamma` are critical for SVM performance. Consider using a grid search to find the optimal combination.

---

> [!question]
> ### Exercise 2: Crop Type Mapping with Random Forest and Time Series
> Using a time series of 10 co-registered `==Sentinel-1==` SAR images acquired over a single growing season, your goal is to identify different crop types (e.g., corn, wheat, soy). You have ground truth data indicating the crop type for several fields.
>
> Develop a workflow that:
> 1.  Generates a temporal signature (e.g., mean, max, standard deviation of `==backscatter==` over time) for each pixel.
> 2.  Uses these temporal features to train a `==Random Forest==` classifier.
> 3.  Discuss why a time-series approach is more effective for this task than a single-date image, relating your answer to crop `==phenology==`.
>
> > [!TIP] Hint
> > Feature engineering is key here. Instead of using raw backscatter values from each date, creating statistical features from the time series can make your model more robust and effective.

---

> [!question]
> ### Exercise 3: Ship Detection in VHR Imagery
> You have a high-resolution satellite image of a busy port. Your objective is to automatically detect and count the ships.
>
> Propose a method using a `==pre-trained model==` for `==object detection==`, such as YOLO (You Only Look Once) or Faster R-CNN.
>
> Describe the key steps you would take, including:
> -   How you would prepare the imagery (e.g., tiling).
> -   The concept of fine-tuning the model on a small, custom dataset of ships.
> -   How you would evaluate the model's performance using metrics like Intersection over Union (IoU) for the `==bounding boxes==`.
>
> > [!TIP] Hint
> > A model pre-trained on a general dataset like COCO might not perform perfectly on overhead satellite imagery. This process, known as transfer learning, adapts the powerful features learned from the general dataset to your specific remote sensing task.

---

> [!question]
> ### Exercise 4: Burn Scar Delineation with U-Net
> Following a major wildfire, you need to accurately map the extent of the `==burn scar==`. You are given a post-fire Landsat 8 image and a set of manually delineated burn scar masks for training.
>
> Your task is to train a `==U-Net==` model for `==semantic segmentation==`.
> 1.  Prepare your data by creating image patches and corresponding binary masks (1 for burned, 0 for not burned).
> 2.  Train the U-Net model.
> 3.  Apply the model to a new, unseen area of the post-fire image to produce a `==pixel-wise classification==` map.
> 4.  Briefly explain why the `==encoder-decoder architecture==` of the U-Net is particularly well-suited for this task.
>
> > [!TIP] Hint
> > Data augmentation is crucial when training deep learning models, especially with limited data. Apply random rotations, flips, and brightness adjustments to your training patches to make your model more robust.

---

> [!question]
> ### Exercise 5: Unsupervised Change Detection for Urban Growth
> You have two cloud-free Landsat images of a city, one from 2010 and one from 2020. Your goal is to map urban expansion using an `==unsupervised learning==` approach.
>
> Create a change map by:
> 1.  Ensuring the images are radiometrically comparable.
> 2.  Creating a `==difference image==` (e.g., by subtracting the NDVI of 2010 from 2020).
> 3.  Applying `==K-Means clustering==` to the difference image with K=3 to group pixels into "negative change," "no change," and "positive change" (urban growth).
>
> > [!TIP] Hint
> > Before differencing, it's vital to perform relative radiometric normalization between the two images to ensure that detected changes are due to land cover transitions and not atmospheric or illumination differences.

---

> [!question]
> ### Exercise 6: Mineral Mapping with Hyperspectral Data
> You are working with an AVIRIS `==hyperspectral imagery==` cube of a mining district. The high number of spectral bands (224) introduces the `==curse of dimensionality==`.
>
> Your task is to:
> 1.  Apply `==Principal Component Analysis (PCA)==` to reduce the dimensionality of the data. Justify your choice for the number of components to retain.
> 2.  Use the resulting principal components as input features for a `==K-Nearest Neighbors (KNN)==` classifier to map different mineral types, using a provided spectral library as training data.
>
> > [!TIP] Hint
> > Visualize the first three principal components as an RGB composite image. You will often see that this single image reveals more geological variation than any true-color composite from the original bands.

---

> [!question]
> ### Exercise 7: Estimating Soil Moisture with Regression
> Instead of classifying pixels, your goal is to predict a continuous variable. You have a dataset combining Sentinel-1 (SAR) and Sentinel-2 (multispectral) data, along with in-situ `==soil moisture==` point measurements.
>
> Use a `==Gradient Boosting==` machine or another regression model to:
> 1.  Train a model that takes pixel values from the satellite data as input and predicts soil moisture.
> 2.  Evaluate the model's performance using metrics like `==Mean Absolute Error (MAE)==` or `==Root Mean Squared Error (RMSE)==`.
> 3.  Create a map showing the spatial distribution of the estimated soil moisture.
>
> > [!TIP] Hint
> > Both optical (e.g., vegetation indices) and SAR data are sensitive to soil moisture, but in different ways. Combining them can create a more powerful predictive model. Think about which bands or indices would be the most informative features.

---

> [!question]
> ### Exercise 8: Conceptual Design for Deep Learning Pansharpening
> `==Pansharpening==` aims to fuse a high-resolution panchromatic band with lower-resolution multispectral bands to create a high-resolution color image. Traditionally, this is done with algorithmic methods.
>
> Conceptually design a deep learning approach for this task. Describe:
> -   A suitable network architecture (e.g., a `==super-resolution==` CNN).
> -   The inputs and the desired output of the network.
> -   The loss function(s) needed to ensure both high `==spatial detail==` and good `==spectral fidelity==`.
>
> > [!TIP] Hint
> > Consider Wald's protocol for evaluating pansharpening quality. You can degrade original multispectral data to create a training set, allowing you to compare your model's output to the ground truth original image.

---

> [!question]
> ### Exercise 9: Data Augmentation for Scarce Targets
> You need to train a CNN to detect small, newly-formed gullies from VHR aerial imagery, but you only have 50 examples. Training a model on such a small dataset will almost certainly lead to `==overfitting==`.
>
> Propose and justify four `==data augmentation==` techniques you would apply to your training images and masks to artificially expand your dataset. Be specific to the remote sensing context.
>
> > [!TIP] Hint
> > Go beyond simple geometric transformations like rotation. Think about `==radiometric augmentation==`. How could you simulate different lighting conditions, atmospheric haze, or seasonal color variations to make your model more robust?

---

> [!question]
> ### Exercise 10: Explaining a "Black Box" Model with XAI
> You have trained a high-accuracy deep learning model that identifies areas at high risk of landslides. A city planner asks you *why* the model flagged a specific hillside as high-risk. Simply stating the model's confidence score is not enough.
>
> Describe how you would use an `==Explainable AI (XAI)==` technique, like `==SHAP==` or `==LIME==`, to provide an interpretation.
>
> Your explanation should cover:
> -   What `==feature importance==` means in the context of an input image.
> -   How you would visualize the XAI output to be understandable for a non-expert.
>
> > [!TIP] Hint
> > The output for an image is often a heatmap overlaid on the original image. This heatmap highlights the pixels (or superpixels) that most strongly influenced the model's decision, providing a direct visual clue for `==model interpretability==`.