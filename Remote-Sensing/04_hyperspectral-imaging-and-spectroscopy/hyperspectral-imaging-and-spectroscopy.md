---
publishable: false
tags: []
date_updated: 2025-07-22
author: Generated by AI
---

# Hyperspectral Imaging and Spectroscopy
> **Learning Objective:** Covers the analysis of high-dimensional hyperspectral data, including spectral unmixing, endmember analysis, and advanced classification methods for detailed material and vegetation identification.

## Introduction
While multispectral imaging provides us with valuable information across a handful of broad spectral bands, hyperspectral imaging elevates our analytical capabilities to an entirely new level. Imagine being able to see not just in "red," "green," and "blue," but in hundreds of specific, narrow shades of color simultaneously. This is the essence of hyperspectral remote sensing. This chapter moves beyond simple band-ratio analysis and introduces you to the techniques required to harness the power of this high-dimensional data. We will deconstruct the hyperspectral "data cube," learn how to identify the "pure" spectral components within a single pixel through endmember analysis and spectral unmixing, and finally, explore advanced classification algorithms designed specifically to distinguish materials with a level of detail previously unattainable. These methods are foundational for precise applications such as identifying specific mineral deposits, assessing subtle variations in vegetation stress, or differentiating between man-made materials in an urban landscape.

---

## Topic 1: The Hyperspectral Data Cube and Spectral Signatures
At the core of hyperspectral imaging is the **data cube**. Unlike a standard 2D grayscale image (with x, y coordinates) or a 3D multispectral image (with x, y, and a few bands), the hyperspectral data cube is a three-dimensional block of data with two spatial dimensions (x, y) and one spectral dimension (lambda, λ). Think of it as a stack of hundreds of perfectly co-registered images, where each image in the stack corresponds to a very narrow, contiguous wavelength band.

If we were to pick a single pixel in this data cube and "drill down" through the spectral dimension, we would extract a continuous curve representing the reflectance (or radiance) of that specific point on the ground across hundreds of wavelengths. This curve is known as a **spectral signature** or **spectral profile**.

The power of hyperspectral data lies in the detail of these signatures. In multispectral data, a broad "red" band might average the response over a 60-nanometer range, potentially masking subtle features. In hyperspectral data, we might have six 10-nanometer bands covering that same range. This high spectral resolution allows us to identify specific absorption features—narrow troughs in the spectral signature caused by the molecular bonds and chemical composition of the material being observed.

For example, healthy vegetation has a characteristic signature: low reflectance in the blue and red regions (due to chlorophyll absorption for photosynthesis), a sharp increase at the "red edge" (~700 nm), and high reflectance in the near-infrared (NIR). With hyperspectral data, we can analyze the precise position and depth of the chlorophyll absorption features or water absorption features in the short-wave infrared (SWIR), allowing us to diagnose plant stress or water content with far greater accuracy than an NDVI calculation alone could provide. Similarly, different minerals have unique absorption features at specific wavelengths, acting as diagnostic fingerprints for their identification.

> [!NOTE] Guided Application Exercise
> **Problem:** An analyst has extracted the spectral signature from a single pixel in a hyperspectral image captured over an agricultural area. The signature (plotted as Reflectance vs. Wavelength) shows a distinct dip around 670 nm, a very steep rise between 690 nm and 740 nm, and strong absorption features centered at 970 nm and 1200 nm. Based on these features, what can you infer about the material in this pixel?
>
> **Resolution Process:**
> 1.  **Step 1: Analyze the Visible and Red Edge Regions.** Identify the features in the visible spectrum (400-700 nm) and the transition to the near-infrared. The dip at 670 nm is a classic chlorophyll absorption peak. The steep rise immediately following this is known as the "red edge," a hallmark of healthy, photosynthetically active vegetation.
> 2.  **Step 2: Analyze the Infrared Regions.** Identify features in the near-infrared (NIR) and short-wave infrared (SWIR). The features at 970 nm and 1200 nm are well-known water absorption bands. The presence of these distinct absorption troughs indicates that the material contains significant amounts of liquid water.
> 3.  **Step 3: Synthesize the Findings.** Combine the observations from both spectral regions. The combination of strong chlorophyll absorption and prominent water absorption bands is uniquely characteristic of living, healthy vegetation.
>
> **Solution:**
> The material in the pixel is healthy, well-watered vegetation. The 670 nm absorption is due to chlorophyll-a, the steep red edge indicates high cellular density in the leaves, and the absorption features at 970 nm and 1200 nm are direct evidence of water content within the plant tissue. A dry or dead plant would have a much less pronounced red edge and weaker water absorption features.

---

## Topic 2: Endmember Analysis and Spectral Unmixing
A common challenge in remote sensing is the **mixed pixel problem**. A single sensor pixel, which might cover an area from 1 m² to over 30 m² on the ground, rarely contains just one type of material. It might be a mix of soil, grass, and a patch of pavement. In multispectral analysis, this pixel is simply classified as the dominant material or as a generic "mixed urban" class. Hyperspectral imaging, however, allows us to do better.

**Spectral unmixing** is a family of techniques used to decompose the spectral signature of a mixed pixel into a set of constituent "pure" spectra and their corresponding abundances. The foundational concept is that of an **endmember**. An endmember is an idealized, pure spectral signature for a single material (e.g., pure asphalt, pure oak leaf, pure quartz sand).

The most common unmixing model is the **Linear Mixing Model (LMM)**. It assumes that the reflectance in a mixed pixel is a linear combination of the reflectance of the endmembers present within that pixel, weighted by their fractional area. The model can be expressed as:

`R_pixel = Σ (f_i * E_i) + ε`

Where:
-   `R_pixel` is the spectral signature vector of the mixed pixel.
-   `E_i` is the spectral signature vector of the *i*-th endmember.
-   `f_i` is the abundance fraction of the *i*-th endmember (the value we want to find).
-   `ε` is the error or residual term.

The abundance fractions `f_i` are also subject to two constraints:
1.  **Abundance Sum-to-One Constraint:** `Σ f_i = 1` (All fractions must add up to 100%).
2.  **Abundance Non-Negativity Constraint:** `f_i ≥ 0` (You can't have a negative amount of a material).

The process typically involves two stages:
1.  **Endmember Extraction:** Identifying the pure material spectra (the `E_i` values) from the image itself. Algorithms like the Pixel Purity Index (PPI) or N-FINDR are used to find the most "spectrally extreme" pixels in the data cube, which are assumed to be the best candidates for endmembers.
2.  **Fractional Abundance Estimation:** Once the endmembers are defined, an inversion algorithm (like a least-squares fit) is applied to every pixel in the image to solve for the abundance fractions (`f_i`) that best reconstruct the pixel's original spectrum. The output is not a single classification map, but rather a series of "abundance maps," one for each endmember, showing the percentage of that material in every pixel.

> [!NOTE] Guided Application Exercise
> **Problem:** A pixel in a hyperspectral image has a reflectance of 0.3 at 850 nm. You have identified two relevant endmembers for this scene: "Dry Soil" and "Healthy Grass." At 850 nm, the Dry Soil endmember has a reflectance of 0.1, and the Healthy Grass endmember has a reflectance of 0.7. Using a simplified linear mixing model (and ignoring other wavelengths and endmembers for this exercise), calculate the abundance fractions of soil and grass in the pixel.
>
> **Resolution Process:**
> 1.  **Step 1: Set up the Linear Mixing Equation.** Let `f_grass` be the fraction of grass and `f_soil` be the fraction of soil. The equation for the pixel's reflectance is:
>     `R_pixel = (f_grass * R_grass) + (f_soil * R_soil)`
>     `0.3 = (f_grass * 0.7) + (f_soil * 0.1)`
> 2.  **Step 2: Apply the Sum-to-One Constraint.** We know that the fractions must add up to 1:
>     `f_grass + f_soil = 1`
>     This can be rearranged to express one variable in terms of the other: `f_soil = 1 - f_grass`.
> 3.  **Step 3: Substitute and Solve for One Variable.** Substitute the expression from Step 2 into the equation from Step 1:
>     `0.3 = (f_grass * 0.7) + ((1 - f_grass) * 0.1)`
>     `0.3 = 0.7*f_grass + 0.1 - 0.1*f_grass`
>     `0.2 = 0.6*f_grass`
>     `f_grass = 0.2 / 0.6 = 1/3`
> 4.  **Step 4: Solve for the Other Variable.** Now use the result from Step 3 and the constraint from Step 2 to find the fraction of soil:
>     `f_soil = 1 - f_grass = 1 - 1/3 = 2/3`
>
> **Solution:**
> The pixel is composed of approximately **33.3% Healthy Grass** and **66.7% Dry Soil**. The final output would be two abundance values for this pixel, which, when applied across the entire image, would generate a grass abundance map and a soil abundance map.

---

## Topic 3: Advanced Classification Methods for Hyperspectral Data
With hundreds of spectral bands, traditional classification algorithms used for multispectral data (like Maximum Likelihood) can become ineffective. This is due to the **curse of dimensionality**, where the amount of training data required to adequately define class signatures increases exponentially with the number of features (bands). Furthermore, these classifiers often do not fully leverage the contiguous nature of the spectral signature. Hyperspectral classification therefore relies on specialized algorithms.

### Spectral Angle Mapper (SAM)
The **Spectral Angle Mapper (SAM)** is a physically-based classification method that is robust to illumination differences. Topographic shadows or changes in sun angle can change the *brightness* (magnitude) of a pixel's spectral vector, but not its fundamental *shape*. SAM cleverly exploits this by treating the spectra as vectors in an n-dimensional space (where n is the number of bands) and calculating the angle between a pixel's spectral vector and a reference (or endmember) spectral vector.

The algorithm is simple:
1.  Reference spectra for materials of interest are collected (from a spectral library or from endmembers extracted from the image).
2.  For each pixel in the image, the algorithm calculates the spectral angle (α) between its vector (`t`) and each reference vector (`r`). The angle is calculated using the dot product formula:
    `α = arccos( (t ⋅ r) / (||t|| ||r||) )`
3.  A smaller angle indicates a better match. The pixel is assigned to the class of the reference spectrum with which it has the smallest angle. A maximum angle threshold can also be set to leave very dissimilar pixels unclassified.

Because SAM uses the angle and not the vector length, a brightly lit patch of concrete and a shaded patch of concrete will ideally have a very small angle between them and be classified as the same material.

### Machine Learning Approaches (e.g., SVM)
More recently, machine learning algorithms have become dominant in hyperspectral classification. **Support Vector Machines (SVM)** are particularly well-suited for this task. An SVM is a supervised classifier that aims to find an optimal hyperplane (a decision boundary) that separates classes in the high-dimensional feature space.

Key advantages of SVMs for hyperspectral data include:
-   **Effectiveness in High Dimensions:** They perform very well even when the number of features (bands) is much larger than the number of training samples, directly combating the curse of dimensionality.
-   **Non-linear classification:** Using the "kernel trick," SVMs can efficiently perform non-linear classification, implicitly mapping the input features into very high-dimensional spaces to find a linear separator. This allows them to model complex relationships between spectra and classes.

The process involves providing the SVM with a set of labeled training pixels (e.g., pixels you know are "pine tree," "asphalt," "water"). The algorithm then learns the optimal decision boundary and can apply it to classify the rest of the image.

> [!NOTE] Guided Application Exercise
> **Problem:** An analyst is using SAM to classify a pixel. The pixel's spectrum is represented by a simplified 2-band vector `t = [0.2, 0.4]`. There are two reference classes: "Water" with vector `r_water = [0.1, 0.1]` and "Vegetation" with vector `r_veg = [0.1, 0.5]`. To which class should the pixel be assigned?
>
> **Resolution Process:**
> 1.  **Step 1: Visualize the Vectors.** Imagine a 2D graph. The Water vector points from the origin towards (0.1, 0.1), close to the 45-degree line. The Vegetation vector points towards (0.1, 0.5), much more steeply upward. The pixel's vector points towards (0.2, 0.4), which has a similar direction/slope to the vegetation vector. This gives us a qualitative expectation.
> 2.  **Step 2: Calculate the Angle with the Water Reference.** We need to calculate `(t ⋅ r_water)` and the magnitudes `||t||` and `||r_water||`.
>     -   `t ⋅ r_water = (0.2 * 0.1) + (0.4 * 0.1) = 0.02 + 0.04 = 0.06`
>     -   `||t|| = sqrt(0.2² + 0.4²) = sqrt(0.04 + 0.16) = sqrt(0.20) ≈ 0.447`
>     -   `||r_water|| = sqrt(0.1² + 0.1²) = sqrt(0.01 + 0.01) = sqrt(0.02) ≈ 0.141`
>     -   `cos(α_water) = 0.06 / (0.447 * 0.141) ≈ 0.06 / 0.063 ≈ 0.952`
>     -   `α_water = arccos(0.952) ≈ 17.8 degrees`
> 3.  **Step 3: Calculate the Angle with the Vegetation Reference.**
>     -   `t ⋅ r_veg = (0.2 * 0.1) + (0.4 * 0.5) = 0.02 + 0.20 = 0.22`
>     -   `||r_veg|| = sqrt(0.1² + 0.5²) = sqrt(0.01 + 0.25) = sqrt(0.26) ≈ 0.510`
>     -   `cos(α_veg) = 0.22 / (0.447 * 0.510) ≈ 0.22 / 0.228 ≈ 0.965`
>     -   `α_veg = arccos(0.965) ≈ 15.2 degrees`
> 4.  **Step 4: Compare the Angles.** The angle between the pixel and the Vegetation reference (15.2°) is smaller than the angle between the pixel and the Water reference (17.8°).
>
> **Solution:**
> The pixel should be classified as **Vegetation**. Even though the pixel's vector magnitude is different from the reference, its direction in n-dimensional space is more similar to the Vegetation reference vector, demonstrating the core principle of the Spectral Angle Mapper.

---

## Links to Practical Work
- [[Practical Work for remote sensing undergradute]]