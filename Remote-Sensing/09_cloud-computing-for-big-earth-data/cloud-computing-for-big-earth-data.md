---
publishable: false
tags: []
date_updated: 2025-07-22
author: Generated by AI
---

# Cloud Computing for Big Earth Data
> **Learning Objective:** Utilizing cloud-based platforms like Google Earth Engine for large-scale geospatial analysis, enabling planetary-scale research and overcoming local processing and storage limitations.

## Introduction
The field of remote sensing is undergoing a profound transformation, driven by an unprecedented explosion in the volume, variety, and velocity of Earth observation data. Satellites like Landsat and Sentinel now provide global coverage every few days, generating petabytes of data annually. This "Big Earth Data" presents a significant challenge to traditional analysis workflows. In the past, a researcher would spend hours, or even days, downloading a single satellite scene to their local computer, requiring substantial storage space and powerful processing hardware. Scaling this process to analyze an entire country, continent, or even the globe over several decades was, for most, a logistical and computational impossibility.

This chapter introduces the paradigm shift that directly addresses this challenge: cloud computing. By moving the data and the processing capabilities to a centralized, massively parallel computing environment, we can reverse the traditional workflow. Instead of bringing petabytes of data to our single computer, we bring our few kilobytes of code to the data. Platforms like Google Earth Engine (GEE) host analysis-ready replicas of vast public data archives (e.g., the entire Landsat and Sentinel catalogs) and provide the computational power to analyze them in-situ. This chapter will explore the fundamental concepts behind this approach and provide a practical introduction to using GEE to unlock planetary-scale geospatial analysis, freeing us from the constraints of local hardware.

---

## Topic 1: The Traditional Workflow vs. The Cloud-Based Paradigm
For decades, the standard remote sensing workflow has been *data-centric*. The process was dictated by the location and management of the data itself.

**The Traditional, Desktop-Based Workflow:**

1.  **Identify Need:** A researcher identifies a need to analyze a specific geographic area at a specific time.
2.  **Discover and Order Data:** They navigate a data portal (e.g., USGS EarthExplorer) to find and order the required satellite scenes.
3.  **Download:** The scenes, often several gigabytes each, are downloaded to a local machine. This step is time-consuming and dependent on internet bandwidth.
4.  **Store:** The downloaded data consumes significant local hard drive space. Managing multiple scenes, versions, and ancillary data becomes a complex task.
5.  **Pre-process:** The data must be prepared for analysis. This can include atmospheric correction, mosaicking, and subsetting, all of which are computationally intensive and generate intermediate data products, further consuming storage.
6.  **Analyze:** The actual analysis (e.g., classification, change detection) is performed. Processing a single large scene can take hours on a high-end desktop. Scaling up to hundreds of scenes is often impractical.
7.  **Visualize:** The final results are generated and visualized.

This entire workflow is bottlenecked by data transfer, storage, and local processing power. A study of deforestation across the entire Amazon basin over 30 years would be a monumental undertaking for a single researcher or lab.

**The Cloud-Based Paradigm:**

Cloud computing platforms for geospatial analysis, like Google Earth Engine (GEE), fundamentally invert this model. The paradigm shifts from being *data-centric* to *analysis-centric*.

The core principles are:

*   **Data Co-location:** The platform hosts a massive, multi-petabyte catalog of analysis-ready data. The data is already on the server, eliminating the need for downloads. The entire Landsat archive, for instance, is immediately accessible.
*   **Parallel Processing:** Instead of processing pixels one by one on a single CPU, the platform leverages Google's vast computational infrastructure. A request is broken down into many small, independent tasks that are executed simultaneously across thousands of servers. This is known as parallelization.
*   **Server-Side Execution:** Your analysis code (a script) is sent to the data servers. The computation happens "in the cloud," and only the final, much smaller result (e.g., a statistic, a chart, or a processed map layer for visualization) is sent back to your browser.

This new workflow looks like this:

1.  **Write Code:** A researcher writes a script in a web-based IDE (Integrated Development Environment) defining the area of interest, time range, and analytical steps.
2.  **Send Request:** The script is sent to the cloud platform.
3.  **Compute:** The platform's servers access the required data from the catalog and execute the analysis in parallel.
4.  **Receive Result:** The researcher receives the final output—a map layer, a data table, or a chart—almost instantly.

This shift allows a single researcher to perform analyses in minutes that would have previously taken a team of specialists months to complete.

> [!NOTE] Guided Application Exercise
> **Problem:** Load and display a single, recent, low-cloud Landsat 9 image over Mount Fuji, Japan. This simple task highlights the ease of data access without downloading.
>
> **Resolution Process:**
> 1.  **Step 1: Define the Area of Interest (AOI).** We need to tell GEE where to look. We can do this by creating a point geometry centered on Mount Fuji.
> 2.  **Step 2: Access the Image Collection.** We need to access the Landsat 9 Collection 2, Tier 1 dataset.
> 3.  **Step 3: Filter the Collection.** The collection contains all Landsat 9 images globally. We must filter it to find images that:
>     *   Intersect our AOI.
>     *   Fall within a recent date range (e.g., the last year).
>     *   Have low cloud cover (e.g., less than 10%).
> 4.  **Step 4: Select and Display.** From the filtered set, we'll select the single best image (the one with the least clouds) and add it to the map, specifying which bands to display as red, green, and blue for a true-color composite.
>
> **Solution:**
> ```javascript
> // Step 1: Define the Area of Interest (AOI).
> var point = ee.Geometry.Point(138.727, 35.360);
>
> // Step 2: Access the Landsat 9 image collection.
> var l9 = ee.ImageCollection('LANDSAT/LC09/C02/T1_L2');
>
> // Step 3: Filter the collection.
> var filteredCollection = l9
>     // Filter by location (intersects our point)
>     .filterBounds(point)
>     // Filter by a recent date range
>     .filterDate('2023-01-01', '2023-12-31')
>     // Sort by cloud cover property, least cloudy first.
>     .sort('CLOUD_COVER');
>
> // Step 4: Select the best image and display it.
> // .first() gets the least cloudy image from the sorted collection.
> var image = ee.Image(filteredCollection.first());
>
> // Define visualization parameters for a true-color composite.
> // Bands 4, 3, 2 are Red, Green, Blue for Landsat 8/9.
> // We set min/max reflectance values to enhance contrast.
> var visParams = {
>   bands: ['SR_B4', 'SR_B3', 'SR_B2'],
>   min: 0.0,
>   max: 0.3,
> };
>
> // Center the map on our point and add the image layer.
> Map.centerObject(point, 10);
> Map.addLayer(image, visParams, 'Landsat 9 - Mount Fuji');
> ```

---

## Topic 2: Core GEE Concepts: Images, Collections, and Functions
To effectively use Google Earth Engine, you must understand its core data structures and how to manipulate them. The GEE API (Application Programming Interface), primarily accessed via JavaScript or Python, treats geospatial data as server-side objects.

**Images (`ee.Image`)**
An `ee.Image` object in GEE is more than just a picture. It is a multi-band raster dataset. Each band is a two-dimensional grid of pixels, and each pixel has a value. An image also contains metadata, such as the date of acquisition, satellite sensor information, cloud cover percentage, and its geospatial projection.

You can perform numerous operations on an image, such as:
*   **Band Math:** Applying mathematical operations to bands to create new indices. The most common example is the Normalized Difference Vegetation Index (NDVI), calculated as `(NIR - Red) / (NIR + Red)`.
*   **Selection:** Selecting specific bands to work with (`image.select('band_name')`).
*   **Clipping:** Restricting the image to an area of interest (`image.clip(geometry)`).

**Image Collections (`ee.ImageCollection`)**
An `ee.ImageCollection` is a stack or a series of `ee.Image` objects. Think of it as a "lazy" collection of images that share common properties. The entire Landsat 8 archive, for example, is available as an `ImageCollection`. It is "lazy" because the images are not all loaded into memory at once; they are simply pointers to the data in the archive.

This structure is the key to powerful temporal analysis. You can filter a collection based on:
*   **Date:** `filterDate('start_date', 'end_date')`
*   **Location:** `filterBounds(geometry)`
*   **Metadata:** `filter(ee.Filter.lt('CLOUD_COVER', 10))` (filter for metadata property 'CLOUD_COVER' less than 10).

**Mapping a Function over a Collection**
One of the most fundamental and powerful concepts in GEE is the ability to *map* a function over an `ImageCollection`. This means applying the same operation to every single image in the collection, without using a traditional `for` loop. This is a core tenet of parallelization.

For example, if you want to calculate NDVI for every image in a year's worth of Landsat data, you would:
1.  Define a function that takes one image as input and returns the same image with an added NDVI band.
2.  Use the `collection.map(myFunction)` command to apply this function to the entire collection.

GEE handles the parallel execution of this function across all images in the background.

**Reducers (`ee.Reducer`)**
A reducer is used to aggregate data. You can use reducers to combine many values into a single value. Reducers can be applied over:
*   **Time:** To aggregate an `ImageCollection` into a single `ee.Image`. For example, you can create a single image where each pixel is the *median* value of all corresponding pixels in the collection (`collection.median()`). This is a very effective way to create a cloud-free composite image.
*   **Space:** To aggregate the pixel values within a region of an `ee.Image` into a single number (e.g., calculating the average NDVI for a national park). This is done with `image.reduceRegion()`.

These core concepts—Images, Collections, Mapping, and Reducing—form the building blocks for nearly all analyses in Google Earth Engine.

> [!NOTE] Guided Application Exercise
> **Problem:** Calculate and display a median-pixel, cloud-free NDVI composite for the entire country of Costa Rica for the year 2023.
>
> **Resolution Process:**
> 1.  **Step 1: Get the Geometry.** We need a boundary for Costa Rica. GEE has a built-in dataset of countries we can filter to get the correct geometry.
> 2.  **Step 2: Filter the Image Collection.** We'll use the Sentinel-2 collection, filtering it by our Costa Rica geometry and the date range for the full year 2023.
> 3.  **Step 3: Define a Cloud Masking Function.** Sentinel-2 has a quality band (SCL) that identifies clouds. We'll write a function to read this band and mask out cloudy pixels in each image.
> 4.  **Step 4: Define an NDVI Calculation Function.** We'll write a function that takes an image as input and calculates NDVI using the Red (B4) and NIR (B8) bands.
> 5.  **Step 5: Map Functions over the Collection.** We will first map the cloud mask function over the collection, and then map the NDVI calculation function.
> 6.  **Step 6: Reduce the Collection.** We will use a `median()` reducer on the NDVI collection. This will take the stack of all NDVI images from 2023 and compute the median value for each pixel, effectively removing clouds and creating a single, representative NDVI image.
> 7.  **Step 7: Visualize the Result.** We will add the final composite NDVI image to the map with a color palette suitable for vegetation.
>
> **Solution:**
> ```javascript
> // Step 1: Get the geometry for Costa Rica.
> var countries = ee.FeatureCollection('USDOS/LSIB_SIMPLE/2017');
> var costaRica = countries.filter(ee.Filter.eq('country_na', 'Costa Rica'));
>
> // Step 2: Access and filter the Sentinel-2 image collection.
> var s2 = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
>     .filterDate('2023-01-01', '2023-12-31')
>     .filterBounds(costaRica);
>
> // Step 3: Define a function to mask clouds using the SCL band.
> // Values 3, 8, 9, 10, 11 are cloud shadows, clouds, and cirrus.
> function maskS2clouds(image) {
>   var scl = image.select('SCL');
>   var mask = scl.eq(3).or(scl.gte(8).and(scl.lte(11))).not();
>   return image.updateMask(mask);
> }
>
> // Step 4: Define a function to calculate and add an NDVI band.
> // Sentinel-2 NIR band is B8, Red band is B4.
> function addNDVI(image) {
>   var ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI');
>   return image.addBands(ndvi);
> }
>
> // Step 5: Map the functions over the collection.
> var processedCollection = s2
>     .map(maskS2clouds)
>     .map(addNDVI);
>
> // Step 6: Reduce the collection to a single median composite.
> // We select only the NDVI band before reducing.
> var ndviComposite = processedCollection.select('NDVI').median();
>
> // Clip the final image to the borders of Costa Rica.
> var clippedNDVI = ndviComposite.clip(costaRica);
>
> // Step 7: Define visualization parameters and display the result.
> var ndviPalette = ['blue', 'white', 'green']; // Simple palette for NDVI
> Map.centerObject(costaRica, 7);
> Map.addLayer(clippedNDVI, {min: 0, max: 0.8, palette: ndviPalette}, 'Costa Rica NDVI 2023');
> ```

---

## Links to Practical Work
- [[Practical Work for remote sensing undergradute]]