---
publishable: false
tags: []
date_updated: 2025-07-22
author: Generated by AI
---

# UAV and Small Satellite Platforms
> **Learning Objective:** Examines the role of Unmanned Aerial Vehicles (UAVs) and CubeSat constellations in providing high-resolution, on-demand data, including mission planning, data processing, and Structure from Motion (SfM) photogrammetry.

## Introduction
While traditional, large-scale satellite platforms like Landsat and Sentinel have been the bedrock of remote sensing for decades, the field is currently being reshaped by two disruptive technologies: Unmanned Aerial Vehicles (UAVs) and small satellite constellations. These platforms are not merely incremental improvements; they represent a fundamental shift in how we acquire geospatial data. They move us from a paradigm of scheduled, large-area, moderate-resolution captures to one of on-demand, user-defined, and exceptionally high-resolution data acquisition. UAVs offer unprecedented spatial detail (centimeter-level) and temporal flexibility for localized studies, while CubeSat constellations provide near-daily global coverage, revolutionizing our ability to monitor dynamic processes. This chapter delves into the operational principles of these platforms, exploring the critical stages of mission planning, the intricacies of data processing through techniques like Structure from Motion (SfM), and the unique characteristics of data derived from constellations of miniaturized satellites.

---

## Topic 1: Unmanned Aerial Vehicles (UAVs) in Remote Sensing
Unmanned Aerial Vehicles (UAVs), commonly known as drones, have transitioned from a niche technology to a mainstream remote sensing tool. Their value lies in their ability to bridge the gap between ground-based observations and traditional aerial or satellite imagery.

**Platform Types and Characteristics**
UAV platforms primarily fall into two categories, each with distinct advantages for remote sensing applications:

1.  **Multirotor:** These are the most common type of UAV (e.g., quadcopters, hexacopters). They offer excellent maneuverability, including the ability to take off and land vertically (VTOL) and hover in place. This makes them ideal for inspecting complex structures (e.g., bridges, wind turbines) and mapping smaller, intricate areas. Their primary limitation is flight endurance, which is typically in the range of 20-40 minutes, limiting the total area that can be covered in a single flight.
2.  **Fixed-Wing:** These platforms resemble traditional airplanes. They are more aerodynamically efficient, allowing for much longer flight times (often over an hour) and the ability to cover significantly larger areas (e.g., large farms, entire watersheds). However, they require a runway or catapult for launch and a clear area for a belly landing or parachute recovery. They cannot hover, which makes them less suitable for detailed inspection tasks. Hybrid VTOL fixed-wing models exist, attempting to combine the benefits of both designs.

**Sensor Integration**
A UAV is merely the platform; its scientific utility is defined by the sensor it carries. Common sensor payloads include:
*   **RGB Cameras:** Standard high-resolution cameras capturing data in the red, green, and blue portions of the spectrum. These are the workhorses for generating orthomosaics and 3D models via photogrammetry.
*   **Multispectral Sensors:** These capture data in specific, narrow spectral bands, including wavelengths beyond human vision, such as the red-edge and near-infrared (NIR). This data is crucial for calculating vegetation indices like NDVI (Normalized Difference Vegetation Index) to assess crop health, water stress, and biomass.
*   **Thermal Sensors:** These detect emitted longwave infrared radiation, creating images that represent surface temperature. Applications include detecting water leaks in irrigation systems, identifying heat loss from buildings, and monitoring wildlife.
*   **LiDAR (Light Detection and Ranging):** An active sensor that emits laser pulses and measures the return time to calculate precise distances. This allows for the creation of highly accurate digital elevation models (DEMs) and is particularly effective at penetrating vegetation canopies to map the bare earth terrain below.

**Mission Planning Principles**
Successful data acquisition with a UAV hinges on meticulous mission planning, which is typically performed using specialized software (e.g., Pix4Dcapture, DroneDeploy, UgCS). Key parameters to define include:

*   **Area of Interest (AOI):** Defining the precise boundary of the area to be mapped.
*   **Flight Altitude (AGL - Above Ground Level):** This directly controls the **Ground Sampling Distance (GSD)**, which is the real-world size represented by a single pixel in the image. A lower altitude results in a smaller GSD (higher resolution) but requires more flight lines and time to cover the same area.
*   **Image Overlap:** This is perhaps the most critical parameter for photogrammetry.
    *   **Front Overlap (Endlap):** The percentage of overlap between consecutive images along a single flight line.
    *   **Side Overlap (Sidelap):** The percentage of overlap between adjacent flight lines.
    A high overlap (typically 70-85% for both) is essential for the Structure from Motion algorithm (discussed in Topic 2) to successfully reconstruct the scene in 3D. Insufficient overlap will result in gaps in the final model and processing failure.

> [!NOTE] Guided Application Exercise
> **Problem:** You need to map a 500m x 500m (25-hectare) square agricultural field. Your UAV is equipped with a camera that has a 20-megapixel sensor and a lens with a fixed focal length. Your client requires a final orthomosaic with a Ground Sampling Distance (GSD) of 2.5 cm/pixel. Mission planning software calculates that to achieve this GSD, you must fly at an altitude of 90 meters Above Ground Level (AGL). With an 80% front and side overlap, how many images will be captured?
>
> **Resolution Process:**
> 1.  **Step 1: Calculate the image footprint on the ground.** The GSD is the size of one pixel. If the camera sensor is 5472 x 3648 pixels, the ground coverage of a single image at 90m altitude can be calculated.
    *   Image Footprint Width = GSD * Number of pixels (width) = 0.025 m/pixel * 5472 pixels = 136.8 meters
    *   Image Footprint Height = GSD * Number of pixels (height) = 0.025 m/pixel * 3648 pixels = 91.2 meters
> 2.  **Step 2: Calculate the effective distance between images and flight lines.** With 80% overlap, only 20% (1 - 0.80) of the image dimension represents new area.
    *   Distance between photos (along flight line) = Footprint Height * (1 - Front Overlap) = 91.2 m * 0.20 = 18.24 meters
    *   Distance between flight lines = Footprint Width * (1 - Side Overlap) = 136.8 m * 0.20 = 27.36 meters
> 3.  **Step 3: Calculate the number of flight lines and photos per line.** The field is 500m x 500m.
    *   Number of flight lines = Field Width / Distance between flight lines = 500 m / 27.36 m ≈ 18.27. We must round up to ensure full coverage, so **19 flight lines** are needed.
    *   Number of photos per line = Field Length / Distance between photos = 500 m / 18.24 m ≈ 27.41. We round up, so **28 photos per line**.
> 4.  **Step 4: Calculate the total number of images.**
    *   Total Images = Number of flight lines * Number of photos per line = 19 * 28
>
> **Solution:**
> To map the 25-hectare field at the required GSD and overlap, a total of **532 images** will need to be captured. This calculation is fundamental to estimating flight time, data storage needs, and processing requirements before heading to the field.

---

## Topic 2: Structure from Motion (SfM) Photogrammetry
Acquiring hundreds of overlapping images with a UAV is only the first step. The magic of turning these individual, distorted 2D images into a unified, georeferenced 3D point cloud and 2D orthomosaic happens through a processing pipeline known as Structure from Motion (SfM). SfM is a photogrammetric technique that leverages computer vision algorithms to automatically solve for camera positions, orientations, and the 3D structure of the scene simultaneously.

**The SfM Workflow**
While specific software packages (e.g., Agisoft Metashape, PIX4Dmapper) may have different interfaces, the underlying workflow is largely standardized:

1.  **Feature Detection and Matching (Image Alignment):** The process begins by identifying unique keypoints or features in each image. Algorithms like SIFT (Scale-Invariant Feature Transform) are used to find features (e.g., corners of rocks, distinct textures) that are robust to changes in scale, rotation, and illumination. The software then compares every image to every other image, finding matching keypoints across the dataset. The high overlap specified in the mission plan is crucial here, as a single real-world point must be visible in many images from different perspectives.

2.  **Sparse Point Cloud and Camera Pose Estimation:** Using the matched features, the software performs a process called **bundle adjustment**. This is an optimization problem that simultaneously calculates:
    *   The 3D coordinates (X, Y, Z) of each matched keypoint, forming a "sparse point cloud."
    *   The camera's position (X, Y, Z) and orientation (yaw, pitch, roll) for every single image taken.
    This step essentially reconstructs the geometry of the flight and the scene. The result is a low-density, but geometrically correct, 3D representation.

3.  **Georeferencing with Ground Control Points (GCPs):** The sparse cloud is initially in an arbitrary, relative coordinate system. To transform it into a real-world geographic coordinate system (e.g., WGS84 / UTM Zone 10N), we need **Ground Control Points (GCPs)**. These are targets placed on the ground whose precise coordinates have been measured using high-accuracy GPS (like RTK or PPK systems). By identifying the center of these targets in the images, the operator provides the software with the necessary links to anchor the entire model to the Earth's surface. This step is vital for ensuring high absolute accuracy.

4.  **Dense Point Cloud Generation:** Using the now-calibrated camera positions, the software performs a more intensive calculation. It goes back to the images and, for each pixel, attempts to find corresponding pixels in multiple overlapping photos. This multi-view stereo reconstruction process generates a **dense point cloud**, containing millions or even billions of points, each with X, Y, Z coordinates and RGB color information.

5.  **Product Generation (DSM and Orthomosaic):** From the dense point cloud, two primary products are generated:
    *   **Digital Surface Model (DSM):** A raster grid where each cell value represents the elevation of the surface, including features like buildings and trees.
    *   **Orthomosaic:** A single, geometrically corrected composite image of the entire area. Unlike a simple stitched panorama, an orthomosaic has been ortho-rectified to remove image perspective and terrain distortions, resulting in a true-to-scale map.

> [!NOTE] Guided Application Exercise
> **Problem:** You have processed a UAV dataset of a construction site using SfM, but the final orthomosaic appears "warped" and a building's height is measured as 15m in your model, while the architectural plans state it is 20m tall. You did not use any GCPs. What is the most likely cause of these inaccuracies, and what specific phenomenon is at play?
>
> **Resolution Process:**
> 1.  **Step 1: Analyze the problem symptoms.** The symptoms are geometric distortion ("warping") and vertical error (inaccurate height). This points to an issue in the bundle adjustment and georeferencing stage of the SfM workflow.
> 2.  **Step 2: Identify the missing input.** The problem states that no Ground Control Points (GCPs) were used. The processing relied solely on the drone's onboard consumer-grade GPS for image geotags.
> 3.  **Step 3: Connect the missing input to the symptoms.** A model without GCPs is only loosely tied to a real-world coordinate system. The bundle adjustment can resolve the *internal* geometry of the model very well, but without external constraints (GCPs), the entire model can be subject to non-linear deformations. This effect is known as the "doming" or "bowling" effect, where the center of the model may be artificially bowed up or down relative to the edges. This explains both the general "warped" appearance and the specific error in the vertical measurement of the building.
>
> **Solution:**
> The most likely cause is the lack of Ground Control Points (GCPs) in the processing workflow. This has led to a common SfM artifact known as the **"doming effect."** The bundle adjustment, without the absolute positional constraints provided by GCPs, introduces a slight, cumulative error that results in a broad, systematic warping of the 3D model. This non-linear deformation causes significant errors in elevation, explaining why the building height is incorrect. To fix this, the project would need to be reprocessed with the inclusion of several well-distributed, high-accuracy GCPs.

---

## Topic 3: Small Satellites and CubeSat Constellations
Parallel to the UAV revolution, another transformation is occurring in space. The era of large, expensive, multi-decade monolithic satellites is now complemented by the rise of small, agile, and numerous satellites, most notably **CubeSats**.

**The CubeSat Standard**
A CubeSat is a class of miniaturized satellite based on a standardized form factor. The basic unit, a "1U" CubeSat, is a 10x10x10 cm cube with a mass of no more than 2 kg. These units can be combined to create larger satellites (e.g., 3U, 6U, 12U) to accommodate more complex payloads. This standardization has dramatically lowered the cost of building and launching satellites, as they can often "piggyback" on larger rocket launches.

**From Single Satellites to Constellations**
The true power of CubeSats is realized when they are deployed in large numbers as a coordinated **constellation**. Companies like Planet have deployed hundreds of 3U CubeSats (called "Doves") into a sun-synchronous orbit. By having so many satellites spread out along the same orbital path, they function like a line scanner for the entire Earth.

**Key Characteristics and Trade-offs**
CubeSat constellations offer a distinct set of capabilities compared to both UAVs and traditional satellites:

*   **Unprecedented Temporal Resolution:** This is their single greatest advantage. A large constellation can achieve a **daily or near-daily revisit rate** for the entire globe. This is revolutionary for monitoring dynamic processes like deforestation, agricultural cycles, natural disasters, and illegal mining, which are too rapid to be captured effectively by a satellite with a 16-day revisit cycle (like Landsat).
*   **High Spatial Resolution:** While not at the centimeter-level of UAVs, constellations like Planet's offer a spatial resolution of approximately 3-5 meters. This is a significant improvement over freely available moderate-resolution data (e.g., Sentinel-2 at 10m).
*   **Trade-offs:** The small size and lower cost come with compromises.
    *   **Sensor Quality:** The sensors are smaller and often less radiometrically calibrated than those on large, scientific-grade satellites. This can make direct comparison of data over time (e.g., for climate studies) more challenging.
    *   **Shorter Lifespan:** CubeSats lack propulsion and are often in low orbits, meaning they have a shorter operational lifespan (typically 2-5 years) before their orbit decays and they burn up in the atmosphere. The constellation model relies on continuous replenishment with new launches.
    *   **Data Cost:** While cheaper to launch, the high-resolution, high-frequency data from commercial constellations is typically sold under a subscription or license, unlike the free and open data policy of government programs like Landsat.

> [!NOTE] Guided Application Exercise
> **Problem:** An agency is responsible for monitoring post-wildfire vegetation recovery in a remote, 500,000-hectare national park. They need to produce a recovery map every month for two years. They are considering two options: 1) A series of UAV surveys, or 2) A subscription to a CubeSat constellation data service. Analyze the feasibility and suitability of each platform for this specific task.
>
> **Resolution Process:**
> 1.  **Step 1: Analyze the scale of the project.** The area is 500,000 hectares. This is an enormous area. A single UAV flight can cover perhaps 100-200 hectares effectively.
> 2.  **Step 2: Evaluate the UAV option.** To cover 500,000 hectares would require thousands of individual UAV flights. This presents immense logistical challenges: battery charging, data management, personnel time, travel to remote parts of the park, and potential flight restrictions. The cost in terms of labor and time would be prohibitive. While the spatial resolution would be excellent, it is overkill for regional vegetation monitoring and operationally unfeasible at this scale.
> 3.  **Step 3: Evaluate the CubeSat constellation option.** A CubeSat constellation images the entire Earth daily. Accessing the data for the 500,000-hectare AOI is a matter of defining the area and downloading the relevant image tiles. The 3-5 meter resolution is more than adequate for monitoring the regrowth of vegetation at a landscape scale. The high temporal frequency (daily revisits) allows the agency to select the best cloud-free image each month, ensuring a consistent time-series.
>
> **Solution:**
> The **CubeSat constellation is the far more suitable platform** for this application.
> - **UAVs are infeasible** due to the immense scale of the project. The logistical and financial cost of attempting to map 500,000 hectares with UAVs on a monthly basis would be astronomical. UAVs are best suited for small-area, high-detail projects.
> - **CubeSats are ideal** because their primary strength is large-area, high-frequency monitoring. They can easily provide monthly cloud-free imagery for the entire park without any fieldwork. The spatial resolution is appropriate for the task, and the operational model (data subscription) is well-suited for long-term monitoring projects of this magnitude.

---

## Links to Practical Work
- [[Practical Work for remote sensing undergradute]]