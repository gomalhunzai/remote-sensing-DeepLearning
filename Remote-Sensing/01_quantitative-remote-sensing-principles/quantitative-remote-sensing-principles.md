---
publishable: false
tags: []
date_updated: 2025-07-22
author: Generated by AI
---

# Quantitative Remote Sensing Principles
> **Learning Objective:** A review of electromagnetic radiation physics, atmospheric correction models, and sensor calibration with a focus on deriving biophysical parameters from satellite imagery.

## Introduction
While visual interpretation of satellite imagery allows us to identify features like forests, cities, and water bodies, quantitative remote sensing seeks to move beyond simple classification to precise measurement. The goal is to answer not just "What is this?" but "How much of it is there?". This chapter transitions our focus from the qualitative to the quantitative, treating the satellite sensor as a scientific instrument, or a "radiometer in the sky." To achieve this, we cannot simply use the raw pixel values from an image. We must meticulously account for the entire journey of electromagnetic radiation: from its interaction with the Earth's surface, its distortion as it passes through the atmosphere, and finally, its conversion into a digital signal by the sensor. This process involves three critical steps, which form the core of this chapter: understanding the fundamental physics of radiative transfer, correcting for atmospheric interference, and applying sensor-specific calibration. Only by mastering these principles can we transform raw satellite data into reliable, scientifically valid biophysical parameters like vegetation health, water turbidity, or soil moisture content.

---

## Topic 1: The Physics of Surface Reflectance
The foundation of quantitative remote sensing lies in understanding how electromagnetic radiation (EMR) interacts with materials on the Earth's surface. A satellite sensor does not directly measure a physical property like 'greenness' or 'wetness'. It measures *radiance*: the amount of EMR leaving a specific area on the ground in a specific direction towards the sensor.

The key terms to understand are:
- **Irradiance (E):** The amount of EMR from the sun (and scattered from the sky) that *arrives* at a unit area of the surface. It is measured in watts per square meter (W/m²).
- **Radiance (L):** The amount of EMR that is *reflected* from a unit area of the surface towards the sensor within a specific solid angle. It is measured in watts per square meter per steradian (W/m²/sr).
- **Reflectance (ρ):** The fundamental property we seek to measure. It is a unitless ratio describing the efficiency with which a surface reflects EMR. It is calculated as the ratio of the reflected energy (radiance) to the incident energy (irradiance).

In the simplest case, we can think of reflectance as:
`Reflectance (ρ) = Radiance (L) / Irradiance (E)`

However, reality is more complex. Most surfaces are not perfect, uniform reflectors (i.e., they are not Lambertian). The amount of light they reflect depends on the viewing angle of the sensor and the illumination angle of the sun. This directional nature of reflection is described by the **Bidirectional Reflectance Distribution Function (BRDF)**. The BRDF is a physical model that describes how reflectance varies for every possible combination of illumination and viewing angles.

For example, a plowed field will appear brighter or darker depending on whether the sensor is looking "with the sun" (hotspot effect) or "against the sun" (shadowing effect). Water surfaces can exhibit specular reflection (sun glint) at specific sun-sensor geometries. The BRDF accounts for these effects. While a full BRDF inversion is complex, understanding its existence is crucial. It reminds us that to compare images taken at different times of day or from different satellite view angles, we must account for these geometric effects to derive a standardized measure of surface reflectance. This standardized reflectance is the pure, intrinsic property of the surface material that we need for quantitative analysis.

> [!NOTE] Guided Application Exercise
> **Problem:** A remote sensing instrument measures at-surface radiance from a wheat field to be **35 W/m²/sr** in the near-infrared (NIR) band. Simultaneous ground measurements show that the total solar irradiance reaching the field in that same band is **175 W/m²**. Assuming the surface is Lambertian (reflects equally in all directions) for this simplified problem, what is the surface reflectance of the wheat field?
>
> **Resolution Process:**
> 1.  **Step 1:** Identify the given values. We have the outgoing radiance (L) and the incoming irradiance (E).
> 2.  **Step 2:** For a Lambertian surface, the relationship between radiance (L) and total reflected energy (exiting flux) is simplified by a factor of π. The total reflected energy is `L * π`.
> 3.  **Step 3:** Recall the definition of reflectance (ρ) as the ratio of reflected energy to incident energy (irradiance). The formula is `ρ = (L * π) / E`.
> 4.  **Step 4:** Substitute the given values into the formula and calculate the result.
>
> **Solution:**
> Given:
> - Radiance (L) = 35 W/m²/sr
> - Irradiance (E) = 175 W/m²
>
> Formula: `ρ = (L * π) / E`
>
> Calculation: `ρ = (35 W/m²/sr * π) / 175 W/m² ≈ (35 * 3.14159) / 175 ≈ 109.96 / 175 ≈ 0.628`
>
> The surface reflectance of the wheat field in the NIR band is approximately **0.63**, or **63%**. This high value is characteristic of healthy vegetation in the NIR spectrum.

---

## Topic 2: Atmospheric Correction Models
The radiance measured by a satellite sensor is not the true radiance leaving the Earth's surface. As the electromagnetic radiation travels from the surface back up to the sensor, it is altered by the atmosphere. This is a critical problem: the atmosphere acts as a variable, noisy filter between the target and the sensor. To perform quantitative analysis, we *must* remove these atmospheric effects. This process is called **atmospheric correction**.

The two primary atmospheric processes that distort the signal are:
1.  **Scattering:** Gas molecules (like nitrogen and oxygen) and aerosols (like dust, pollen, and pollutants) scatter light.
    -   *Rayleigh Scattering:* Caused by particles much smaller than the wavelength of light (e.g., air molecules). It is most pronounced at shorter wavelengths (blue light), which is why the sky appears blue. This adds a hazy, blueish cast to imagery.
    -   *Mie Scattering:* Caused by particles of a size similar to the wavelength of light (e.g., dust, smoke). It affects a broader range of wavelengths than Rayleigh scattering.
2.  **Absorption:** Atmospheric gases like water vapor (H₂O), carbon dioxide (CO₂), and ozone (O₃) absorb EMR at specific, narrow wavelengths. This causes "dips" in the signal received by the sensor in those spectral regions.

These effects lead to two main problems:
- The atmosphere scatters sunlight *into* the sensor's path that never even reached the target surface. This is called *path radiance* and it artificially brightens pixels, especially dark ones like water.
- The atmosphere scatters and absorbs light *on its way from the target to the sensor*, reducing the signal. This is called *atmospheric attenuation*.

**Atmospheric correction models** are algorithms designed to estimate and remove these effects, converting at-sensor radiance (what the satellite sees) to surface reflectance (the true property of the ground). These models range in complexity:

- **Image-Based Models (Relative Correction):** These models use information from the image itself. The most common is **Dark Object Subtraction (DOS)**. This method assumes that the darkest pixels in an image (e.g., deep, clear water or dense shadows) should have a reflectance value close to zero. Any value measured above zero for these pixels is assumed to be the result of atmospheric path radiance. This path radiance value is then subtracted from every pixel in the band. While simple and fast, DOS is an approximation and doesn't account for all atmospheric effects.

- **Physically-Based Models (Absolute Correction):** These are more sophisticated models that use radiative transfer theory to simulate the physical interactions of EMR with the atmosphere. They require inputs about the atmospheric conditions at the time of image acquisition (e.g., water vapor content, aerosol type, ozone concentration) as well as the sun-target-sensor geometry. Examples of software that implement these models include **MODTRAN**, **6S (Second Simulation of a Satellite Signal in the Solar Spectrum)**, and the tools built upon them like **FLAASH** or **ATCOR**. These models provide the most accurate correction and are essential for rigorous scientific studies.

> [!NOTE] Guided Application Exercise
> **Problem:** You are using the simple Dark Object Subtraction (DOS) method. In your Landsat image band, the raw Digital Number (DN) values range from 68 to 210. You identify a deep, non-silted lake and determine the lowest DN value in that area is **68**. This value is assumed to represent the atmospheric path radiance contribution. Correct a pixel value representing a cornfield, which has a DN of **150**.
>
> **Resolution Process:**
> 1.  **Step 1:** Identify the "dark object" value. This is the minimum value in the scene that is assumed to correspond to zero reflectance. In this case, it is DN = 68. This value represents the additive atmospheric haze (path radiance).
> 2.  **Step 2:** The core principle of DOS is to subtract this haze value from every pixel in the image band.
> 3.  **Step 3:** Apply this subtraction to the target pixel (the cornfield) to get the atmospherically corrected DN.
>
> **Solution:**
> - Dark Object DN (Haze Value) = 68
> - Target Pixel DN (Cornfield) = 150
>
> Corrected DN = Target Pixel DN - Dark Object DN
> Corrected DN = 150 - 68 = 82
>
> The corrected Digital Number for the cornfield pixel is **82**. Note that this is still a DN and not yet a physical unit of reflectance. The next step in a full workflow would be to convert these corrected DNs into reflectance values.

---

## Topic 3: Sensor Calibration and Biophysical Parameter Retrieval
The final step in our quantitative workflow is to convert the raw data from the sensor into physical units and then relate those units to a property on the ground. A satellite sensor's raw output is a **Digital Number (DN)** for each pixel. This is simply an integer value, typically ranging from 0-255 (8-bit), 0-1023 (10-bit), or higher, that represents the brightness recorded. It is not a physical unit.

**Sensor Calibration** is the process of converting these DNs into at-sensor spectral radiance (L). This is a crucial step because the relationship between DN and radiance can change over the lifetime of a sensor as its detectors degrade. Satellite providers supply calibration coefficients for this conversion. The typical formula is a simple linear transformation:

`Radiance (L) = Gain * DN + Offset`

- The **Gain** (or radiance_mult_band_x) is a multiplicative scaling factor.
- The **Offset** (or radiance_add_band_x) is an additive term.

These values are unique for each spectral band and are provided in the image metadata file (e.g., the MTL.txt file for Landsat). By applying this formula, we convert the arbitrary DNs into physically meaningful units of at-sensor radiance (W/m²/sr/μm).

Once we have at-sensor radiance, we can apply the atmospheric correction models from Topic 2 to derive surface reflectance (ρ). With our clean, corrected surface reflectance data, we can finally derive **biophysical parameters**. This is done by using models that link spectral reflectance values to physical properties. These models can be:

- **Empirical Models:** These are based on statistical relationships between reflectance and ground-measured parameters. The most famous examples are **Vegetation Indices (VIs)**. The **Normalized Difference Vegetation Index (NDVI)** is a classic example that uses the contrast between red and near-infrared reflectance to estimate vegetation vigor:
  `NDVI = (ρ_NIR - ρ_Red) / (ρ_NIR + ρ_Red)`
  Healthy vegetation strongly reflects NIR and absorbs red light, leading to high NDVI values (close to +1). Unhealthy vegetation or non-vegetated surfaces have lower values (closer to 0 or below).

- **Physically-Based Models:** These are more complex and attempt to model the physics of light interaction within the canopy or medium itself (e.g., radiative transfer models for plant canopies). They can be used to estimate parameters like **Leaf Area Index (LAI)**, fractional vegetation cover (fCover), or chlorophyll content.

The full quantitative workflow is therefore:
**DN → (Calibration) → At-Sensor Radiance → (Atmospheric Correction) → Surface Reflectance → (Biophysical Model) → Parameter Map (e.g., LAI, NDVI)**

> [!NOTE] Guided Application Exercise
> **Problem:** You have a Landsat 8 pixel. After atmospheric correction, you have the surface reflectance values for the Red band (Band 4) and the Near-Infrared band (Band 5).
> - Red Reflectance (ρ_Red) = 0.08
> - NIR Reflectance (ρ_NIR) = 0.45
>
> Calculate the NDVI for this pixel.
>
> **Resolution Process:**
> 1.  **Step 1:** Recall the formula for NDVI: `NDVI = (ρ_NIR - ρ_Red) / (ρ_NIR + ρ_Red)`.
> 2.  **Step 2:** Identify the given reflectance values for the NIR and Red bands.
> 3.  **Step 3:** Substitute these values into the formula.
> 4.  **Step 4:** Perform the calculation and interpret the result.
>
> **Solution:**
> Given:
> - ρ_NIR = 0.45
> - ρ_Red = 0.08
>
> Formula: `NDVI = (ρ_NIR - ρ_Red) / (ρ_NIR + ρ_Red)`
>
> Calculation:
> `NDVI = (0.45 - 0.08) / (0.45 + 0.08)`
> `NDVI = 0.37 / 0.53`
> `NDVI ≈ 0.698`
>
> The NDVI for this pixel is approximately **0.70**. This high positive value is indicative of healthy, dense vegetation, as expected from the low red reflectance (due to chlorophyll absorption) and high NIR reflectance (due to leaf cellular structure).

---

## Links to Practical Work
- [[Practical Work for remote sensing undergradute]]