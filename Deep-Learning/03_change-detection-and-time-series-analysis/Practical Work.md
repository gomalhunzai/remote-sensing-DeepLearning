---
publishable: false
tags: []
date_updated: 2025-07-22
author: Generated by AI
---

# Exercises (satellite image analyist) â€“ Change Detection and Time-Series Analysis
> Here are 10 practical exercises to apply the concepts from the chapter "Change Detection and Time-Series Analysis" and prepare for the assessment. They are specifically designed for satellite image analyist.

---

> [!question]
> ### Exercise 1: Conceptualizing a Change Detection Baseline
> You are tasked with monitoring ==urban sprawl== in the outskirts of a major city using two Landsat 8 images, one from 2015 and one from 2023.
> 
> 1.  Describe the steps you would take to perform change detection using a **traditional image differencing** technique on the Near-Infrared (NIR) band.
> 2.  Explain at least **three major limitations** of this method.
> 3.  Propose how a ==deep learning model==, such as a U-Net, could overcome these limitations. Focus on how it learns features rather than just relying on pixel value differences.
>
> > [!TIP] Hint
> > Think about sources of "false change" that are not related to urban growth, such as seasonal vegetation differences, shadows, and different sun angles. How would a simple subtraction struggle with these?

---

> [!question]
> ### Exercise 2: Preparing Data for a Siamese Network
> Your goal is to detect new building construction. You have a dataset of co-registered high-resolution satellite image pairs (`t1` and `t2`). To train a ==Siamese Network==, you need to generate image patch pairs with corresponding labels (`change` or `no-change`).
> 
> Outline your data preparation workflow. Specifically, describe:
> - How you would generate the ==image patches== from the larger scenes. What is a reasonable patch size?
> - Your strategy for creating a **balanced dataset** of `change` and `no-change` patches. Why is this important?
> - What data augmentation techniques would be relevant for this task, and why?
>
> > [!TIP] Hint
> > Consider that "change" pixels (new buildings) are often rare compared to "no-change" pixels. How does this imbalance affect model training?

---

> [!question]
> ### Exercise 3: Designing a Deforestation Alert System
> You need to design a model to detect recent ==deforestation== in the Amazon rainforest using Sentinel-2 image pairs. The chosen architecture is a **Siamese Network**.
> 
> - Sketch or describe the architecture of your proposed network.
> - What is the purpose of the ==shared weights== in the convolutional towers?
> - Which ==loss function== would you choose for this task (e.g., Contrastive Loss, Triplet Loss) and why is it suitable for comparing image patch embeddings?
>
> > [!TIP] Hint
> > A Siamese Network learns a similarity function. The goal is to map similar input patches (no-change) to nearby points in the feature space and dissimilar patches (change) to distant points.

---

> [!question]
> ### Exercise 4: Post-Classification Comparison for Land Use Change
> An alternative to direct change detection is **post-classification comparison**. You have two multispectral images from different years and are tasked with mapping the transition from `forest` to `agriculture`.
> 
> 1.  Detail the workflow for this method. What is the first major step you must perform on *each* image independently?
> 2.  Create a hypothetical ==change matrix== showing transitions between four classes: `forest`, `agriculture`, `water`, and `urban`.
> 3.  What is the main drawback of this method, often referred to as ==error propagation==?
>
> > [!TIP] Hint
> > The accuracy of the final change map is highly dependent on the accuracy of the individual classification maps. Consider how an error in the first map affects the final result.

---

> [!question]
> ### Exercise 5: Monitoring Post-Fire Vegetation Recovery
> A large forest area was affected by a wildfire. You have a 5-year time-series of Sentinel-2 images covering the area post-fire. Your task is to analyze vegetation recovery.
> 
> - Describe how you would generate a dense ==NDVI time-series== for a set of pixels within the burned area.
> - How could you use a simple deep learning model, like a ==Multi-Layer Perceptron (MLP)==, to predict the "time to recovery" (i.e., time until NDVI values return to a pre-fire baseline) for a given pixel's time-series?
> - What input features would you feed into the MLP?
>
> > [!TIP] Hint
> > Your input isn't an image, but a sequence of numbers (the NDVI values over time). The model needs to learn the relationship between the shape of this recovery curve and the total time it takes.

---

> [!question]
> ### Exercise 6: Crop Classification with an RNN
> You are given a time-series of satellite images over an agricultural region for a full growing season. Different crops have unique ==phenological cycles== (patterns of greening and browning).
> 
> - Why is a **Recurrent Neural Network (RNN)** or an **LSTM** particularly well-suited for classifying crop types from this temporal data?
> - Describe the structure of the input data for one training sample. Assume you are using the average NDVI, EVI, and SAVI values for a specific field.
> - How does the model's ==memory== help distinguish between two crops that might look spectrally similar at one point in time but have different growth timelines (e.g., winter wheat vs. corn)?
>
> > [!TIP] Hint
> > Think of the input as a sequence of observations. An RNN processes the sequence step-by-step, updating its internal state based on the current observation and its memory of past observations.

---

> [!question]
> ### Exercise 7: Anomaly Detection for Illegal Mining
> Your agency wants to detect ==illegal gold mining==, which causes sudden, localized deforestation and soil disturbance. You have a dense time-series of PlanetScope imagery.
> 
> Propose a deep learning-based **anomaly detection** system.
> 1.  How would you define a "normal" temporal behavior for a pixel in a forested area?
> 2.  Explain how you could train an ==LSTM Autoencoder== to learn this normal behavior.
> 3.  How would you use the trained model's ==reconstruction error== to flag a pixel's time-series as anomalous (potential mining activity)?
>
> > [!TIP] Hint
> > An autoencoder trained only on "normal" data will be very good at reconstructing normal sequences. It will perform poorly (high reconstruction error) when it encounters an unexpected sequence, like a sudden drop in vegetation.

---

> [!question]
> ### Exercise 8: Mapping Flood Extent with a U-Net
> Following a major flood, you need to create a precise map of the inundated areas. You have a pre-flood and post-flood pair of Sentinel-1 SAR images. SAR is ideal because it can see through clouds.
> 
> - How would you structure this problem for a ==U-Net== architecture? What would be the input channels to the network?
> - Explain why the **skip connections** in the U-Net are crucial for producing a precise, high-resolution segmentation map of the floodwater.
> - The output of the U-Net will be a ==semantic change map==. What classes might this map contain?
>
> > [!TIP] Hint
> > Consider stacking the pre- and post-flood images as different channels of a single input. This allows the U-Net to learn the "change features" directly. The classes could be `permanent water`, `newly flooded`, and `no-change land`.

---

> [!question]
> ### Exercise 9: Drought Prediction with Attention Mechanisms
> You are building a model to predict end-of-season crop yield based on a time-series of meteorological and satellite data (e.g., temperature, precipitation, SMAP soil moisture). Not all moments in the growing season are equally important.
> 
> - Explain how a ==transformer-based model== or an RNN with an **attention mechanism** could improve upon a standard RNN for this task.
> - What does it mean for the model to "pay attention" to a specific time step?
> - How could you ==visualize the attention weights== to explain to a stakeholder (e.g., an agronomist) which periods the model found most critical for its prediction?
>
> > [!TIP] Hint
> > For many crops, water stress during a specific growth stage (like flowering) has a much larger impact on final yield than stress at other times. An attention mechanism can learn to automatically identify these critical periods.

---

> [!question]
> ### Exercise 10: Augmenting Data for Rare Event Detection
> You need to train a model to detect collapsed buildings after an earthquake, but real-world training examples are scarce. Your task is to propose a data augmentation strategy using ==synthetic data==.
> 
> - Describe a method to create realistic training pairs of `pre-event` and `post-event` image patches for building collapse.
> - How could a **Generative Adversarial Network (GAN)**, specifically a Pix2Pix-style model, be used to "translate" images of intact buildings into images of damaged/collapsed buildings?
> - What are the main challenges in ensuring the ==synthetic data== is diverse and realistic enough to allow a model to generalize to real post-earthquake imagery?
>
> > [!TIP] Hint
> > You could start with a dataset of intact building footprints (e.g., from OpenStreetMap) and corresponding pre-event satellite imagery. The creative part is simulating the "collapse" texture and appearance in a convincing way.