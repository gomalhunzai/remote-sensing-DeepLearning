---
publishable: false
tags: 
date_updated: 2025-07-22
author: Generated by AI
---

# Exercises (satellite image analyist) â€“ Preprocessing and Data Augmentation for Satellite Images
> Here are 10 practical exercises to apply the concepts from the chapter "Preprocessing and Data Augmentation for Satellite Images" and prepare for the assessment. They are specifically designed for satellite image analyist.

---

> [!question]
> ### Exercise 1: Radiometric Correction Pipeline
> You have received a raw Landsat 9 Level-1 scene (C2 L1) for a time-series analysis of vegetation health. The pixel values are in `==Digital Numbers (DN)==`. To ensure comparability between images taken at different times, you must convert these values to a physical unit.
>
> Outline the key steps and calculations required to convert the DNs to `==Top-of-Atmosphere (TOA) Reflectance==`. Mention the crucial information you would need from the image's `==metadata file (MTL.txt)==`.
>
> > [!TIP] Hint
> > The formula involves multiplicative and additive rescaling factors. Think about where you would find `REFLECTANCE_MULT_BAND_x` and `REFLECTANCE_ADD_BAND_x` in the metadata.

---

> [!question]
> ### Exercise 2: Cloud Masking Strategy
> You are tasked with creating a building footprint dataset from a high-resolution Sentinel-2 image. However, the scene is partially contaminated with scattered clouds and cloud shadows, which could be misclassified as buildings by your model.
>
> Describe two distinct methods for creating a `==binary cloud mask==` to exclude these contaminated pixels before training.
> 1.  A method using the provided `==Quality Assessment (QA) band==`.
> 2.  A method based on `==spectral indices==` or simple band math.
>
> > [!TIP] Hint
> > For the second method, consider which spectral bands are most sensitive to clouds (e.g., Blue, Cirrus) and how their reflectance differs from most land surfaces.

---

> [!question]
> ### Exercise 3: Normalization vs. Standardization
> For a wildfire scar mapping project, you are using a dataset of Sentinel-2 images captured before and after several fire events across different seasons and geographic locations. The illumination conditions vary significantly.
>
> Explain the difference between `==Normalization (Min-Max Scaling)==` and `==Standardization (Z-score Scaling)==`. Which of these two techniques would you choose for this project, and why? Justify your choice in the context of `==multi-temporal analysis==` and model performance.
>
> > [!TIP] Hint
> > Think about how outliers (e.g., a very bright cloud or a dark water body) would be affected by each method. Does one method handle variations in lighting and atmospheric haze better than the other?

---

> [!question]
> ### Exercise 4: Context-Aware Geometric Augmentation
> You are training a U-Net model to segment road networks from 50cm resolution aerial imagery. To increase the size and diversity of your training dataset, you decide to apply `==geometric augmentations==`.
>
> List three geometric augmentations that are appropriate for this task. Then, name one common geometric augmentation that would be **inappropriate** and explain why it could harm your model's performance.
>
> > [!TIP] Hint
> > Satellite and aerial images have a consistent top-down perspective. How would an augmentation that violates this real-world assumption affect the model's learning?

---

> [!question]
> ### Exercise 5: Simulating Environmental Variations with Color Augmentation
> Your deep learning model for land cover classification performs well on images from the dry season but struggles with images from the wet season due to changes in vegetation color and atmospheric haze.
>
> Explain how randomly adjusting `==brightness==`, `==contrast==`, and `==saturation==` during training can help your model become more robust to these seasonal and atmospheric variations. Describe a specific example for each parameter.
>
> > [!TIP] Hint
> > Think of a hazy day as having lower contrast, or the vibrant green of the wet season as having higher saturation. How can you simulate these effects on your dry-season images?

---

> [!question]
> ### Exercise 6: Patch Extraction for Object Detection
> You have a single, very large, high-resolution WorldView-3 image (30cm GSD) of a port, and your task is to train a model to detect shipping containers. A deep learning model cannot process the entire image at once.
>
> Design a `==patch extraction==` (or "tiling") strategy. Specify your choices for:
> -   `==Patch Size==` (e.g., 256x256, 512x512)
> -   `==Stride==` (or overlap)
> -   How you will handle incomplete patches at the image borders.
>
> Justify your choice of patch size in relation to the target objects (shipping containers).
>
> > [!TIP] Hint
> > Consider the average size of a shipping container in pixels in your 30cm GSD image. The patch should be large enough to contain the object with context, but small enough for efficient processing. Overlap is key to not missing objects on patch edges.

---

> [!question]
> ### Exercise 7: Augmentation for Class Imbalance
> After a flood event, you are tasked with identifying damaged buildings from post-event aerial imagery. In your dataset of image patches, the "damaged building" class is extremely rare, making up only 2% of the samples. This `==class imbalance==` is causing your model to perform poorly.
>
> Propose a data augmentation strategy focused on the `==minority class==` to mitigate this issue. How is this different from simply duplicating the existing "damaged" samples?
>
> > [!TIP] Hint
> > Instead of just making copies, think about how you can create *new, unique* examples of damaged buildings by applying a variety of strong geometric and color augmentations only to the minority class samples.

---

> [!question]
> ### Exercise 8: SAR Preprocessing Pipeline
> You need to prepare a Sentinel-1 Ground Range Detected (GRD) scene for a deep learning model that maps deforestation. Unlike optical data, Synthetic Aperture Radar (SAR) data has unique characteristics that must be addressed.
>
> List and briefly describe the essential preprocessing steps you would apply in sequence to the raw SAR data. Your pipeline should include at least four steps.
>
> > [!TIP] Hint
> > Your pipeline should address inherent image noise (`==speckle filtering==`), convert values to a meaningful backscatter unit (`==radiometric calibration==`), and correct for geometric distortions caused by terrain (`==terrain correction==`).

---

> [!question]
> ### Exercise 9: Leveraging Pansharpening
> You are working on a project to count individual trees in a mixed-use plantation using Planetscope imagery, which provides a 3m multispectral product and a higher-resolution panchromatic band. The 3m resolution makes it difficult to distinguish between closely packed tree crowns.
>
> Explain the concept of `==pansharpening==`. How could you use it as a preprocessing step to improve the input data for your tree counting model? What is the main benefit it provides for this specific task?
>
> > [!TIP] Hint
> > Pansharpening is a fusion technique. Think about how you can combine the "what" (color information from multispectral bands) with the "where" (spatial detail from the panchromatic band).

---

> [!question]
> ### Exercise 10: Designing a Domain-Specific Augmentation
> You are building a model to detect signs of crop stress from UAV-based multispectral imagery. A common issue in your operational environment is sensor lens flare when the UAV turns towards the sun, which sometimes causes the model to produce false positives.
>
> Design a `==custom, domain-specific==` data augmentation technique to simulate this lens flare effect. Describe how you would implement it. The goal is to make the model learn to ignore this artifact.
>
> > [!TIP] Hint
> > Be creative. You could programmatically generate synthetic flare artifacts (e.g., bright radial gradients, polygonal shapes) and randomly overlay them onto your training images with varying intensity and opacity.