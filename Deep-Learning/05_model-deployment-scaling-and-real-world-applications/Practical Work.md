---
publishable: false
tags: []
date_updated: 2025-07-22
author: Generated by AI
---

# Exercises (satellite image analyist) â€“ Model Deployment, Scaling, and Real-World Applications
> Here are 10 practical exercises to apply the concepts from the chapter "Model Deployment, Scaling, and Real-World Applications" and prepare for the assessment. They are specifically designed for satellite image analyist.

---

> [!question]
> ### Exercise 1: Containerize a Flood Mapping Model
> You have been given a pre-trained Keras/TensorFlow model (`flood_model.h5`) that performs semantic segmentation on Sentinel-1 SAR images to identify flooded areas. Your task is to create a `Dockerfile` to containerize this model and its dependencies.
> 
> Your `Dockerfile` must:
> 1.  Start from a suitable Python base image.
> 2.  Copy the model file and a `requirements.txt` file into the container.
> 3.  Install all necessary Python libraries, including `tensorflow`, `rasterio`, and `numpy`.
> 4.  Define the `==command==` to run a Python script that loads the model (you don't need to write the script, just reference it, e.g., `app.py`).
>
> > [!TIP] Hint
> > Think about the layers in your `Dockerfile`. Why is it more efficient to copy `requirements.txt` and run `pip install` *before* copying the rest of your application code and model?

---

> [!question]
> ### Exercise 2: Create a Model Inference API
> Using the containerized model from Exercise 1, you now need to expose its functionality via a web API. Your task is to design the specification for a `==REST API==` endpoint using `FastAPI`.
> 
> Describe the following for an endpoint named `/predict`:
> -   **HTTP Method:** (e.g., POST, GET)
> -   **Input:** How would the client send a satellite image patch? (e.g., JSON with a base64 encoded string, or a direct file upload). Justify your choice.
> -   **Output:** What would the JSON response look like? It should return a binary mask of the flood prediction and a `==confidence score==`.
> -   **Error Handling:** What HTTP status code should be returned if the input image is in the wrong format or size?

---

> [!question]
> ### Exercise 3: Batch Processing a Full Sentinel-2 Scene
> You have deployed your land cover classification model as a web service. Now, a client wants you to classify an entire Sentinel-2 scene (approx. 100km x 100km, ~700MB GeoTIFF). A single request would be too large and time-out.
> 
> Outline a Python script that would solve this problem. Your description should detail the following steps:
> 1.  How to read and `==tile==` the large GeoTIFF into smaller, manageable patches (e.g., 256x256 pixels) using a library like `Rasterio`.
> 2.  How to send these patches to your model's API endpoint `==concurrently==` to speed up the process.
> 3.  How to `==stitch==` the classified patches back together into a single, complete classification map.

---

> [!question]
> ### Exercise 4: Design a Serverless Architecture for Deforestation Alerts
> The World Resources Institute wants a system that automatically detects new deforestation events in the Amazon rainforest. As soon as a new Landsat 8 scene is made available in an AWS S3 bucket, it should be analyzed.
>
> Design a `==serverless architecture==` using AWS services to achieve this. List the key components and describe how they interact with each other.
>
> > [!TIP] Hint
> > Your design should include an S3 bucket, a service to trigger the analysis, a service to run the computation (your model), and potentially a notification service. Think about `S3 Event Notifications` and `AWS Lambda`.

---

> [!question]
> ### Exercise 5: Investigating Model Degradation (Data Drift)
> Your deployed ship detection model, which had 95% accuracy on the test set, is now performing poorly in production. You suspect `==data drift==` or `==concept drift==`.
> 
> Create a checklist of at least five things you would investigate to diagnose the problem. For each item, specify the data or metric you would analyze.
>
> *Example: 1. Input Image Brightness: Analyze the histogram of pixel values for new images and compare it to the training data's histogram.*

---

> [!question]
> ### Exercise 6: Blue-Green Deployment for a Building Footprint Model
> You have developed a significantly improved version of a building footprint extraction model. You need to deploy it to production, replacing the old version, with zero downtime and the ability to quickly roll back if issues arise.
> 
> Explain how you would use a `==blue-green deployment==` strategy to accomplish this. Describe what the "blue" and "green" environments would represent in your satellite imagery processing pipeline and how you would switch traffic between them.

---

> [!question]
> ### Exercise 7: Edge Computing for Precision Agriculture
> A client needs to monitor crop health in near real-time using multispectral drone imagery. The fields are in a remote area with unreliable internet, so cloud processing is not always an option.
> 
> Propose a solution using `==edge computing==`.
> 1.  What kind of hardware would you deploy on-site? (e.g., NVIDIA Jetson, Raspberry Pi with an accelerator).
> 2.  What is the main challenge of running a deep learning model on such hardware?
> 3.  Name one technique, such as `==model quantization==` or `==pruning==`, you would use to optimize your model for the edge device and explain what it does.

---

> [!question]
> ### Exercise 8: Designing a CI/CD Pipeline
> To improve reliability and development speed, your team decides to adopt a `==CI/CD==` (Continuous Integration/Continuous Deployment) approach for a road network extraction model.
>
> List and briefly describe the key stages of a CI/CD pipeline for this project, starting from a developer pushing code to a Git repository and ending with the model being deployed to a staging environment.

---

> [!question]
> ### Exercise 9: Scaling Analysis with Distributed Computing
> Your task is to analyze changes in snow cover over the entire Alps region for the last 5 years using daily MODIS imagery. This represents a petabyte-scale dataset that cannot be processed on a single machine.
>
> Explain how you would use a `==distributed computing==` framework (like Dask or Apache Spark) along with a `==data cube==` abstraction to perform this analysis efficiently. What are the key benefits of this approach compared to downloading and processing files one by one?
>
> > [!TIP] Hint
> > Focus on the concept of `==lazy evaluation==` and how these frameworks can build a task graph to optimize operations across a distributed cluster of machines without moving unnecessary data.

---

> [!question]
> ### Exercise 10: Cloud Cost Optimization for a Monitoring Service
> Your wildfire monitoring service runs on a major cloud provider (AWS, GCP, or Azure). It continuously processes new satellite imagery, and the monthly bill is alarmingly high.
>
> Identify three distinct areas in your deployment and operations where you could implement `==cost optimization==` strategies. For each area, describe the specific action you would take.
>
> *Example Areas: Compute, Storage, Data Transfer.*