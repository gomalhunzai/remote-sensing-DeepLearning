---
publishable: false
tags: []
date_updated: 2025-07-22
author: Generated by AI
---

# Exercises (satellite image analyist) â€“ Working with Multispectral and SAR Data
> Here are 10 practical exercises to apply the concepts from the chapter "Working with Multispectral and SAR Data" and prepare for the assessment. They are specifically designed for satellite image analyist.

---

> [!question]
> ### Exercise 1: Visualizing Agricultural Health with False-Color Composites
> You are given a Sentinel-2 multispectral image tile over an agricultural region. Your task is to create a ==False-Color Composite (FCC)== to better distinguish between different crop types and assess their health.
>
> 1.  Load the required bands: Near-Infrared (NIR), Red, and Green.
> 2.  Stack these bands in the order ==NIR, Red, Green== to create the composite image.
> 3.  Analyze the resulting image. How does healthy vegetation appear compared to bare soil or less healthy crops? Document your observations.
>
> > [!TIP] Hint
> > Healthy vegetation reflects strongly in the NIR spectrum. By placing the ==NIR band== in the red channel of the RGB image, healthy plants will appear in bright shades of red.

---

> [!question]
> ### Exercise 2: Speckle Noise Reduction in SAR Imagery
> You have received a Sentinel-1 SAR image of an urban area. The image is affected by significant ==speckle noise==, which complicates feature extraction. Your goal is to apply a filter to reduce this noise.
>
> 1.  Load the single-band SAR intensity image.
> 2.  Apply a ==Lee Filter== with a window size of 7x7.
> 3.  Visually compare the original and the filtered image side-by-side.
> 4.  Explain why speckle reduction is a critical pre-processing step before feeding SAR data into a deep learning model for tasks like building footprint segmentation.
>
> > [!TIP] Hint
> > Speckle is a granular noise that inherently exists in SAR data. Filtering aims to smooth this noise while preserving important edges and textures. Look for a function like `skimage.filters.lee` or its equivalent in your preferred library.

---

> [!question]
> ### Exercise 3: Calculating NDVI for Deforestation Monitoring
> Using Landsat 8 imagery of the Amazon rainforest from two different years, quantify the extent of vegetation loss.
>
> 1.  For each of the two images (pre- and post-deforestation), calculate the ==Normalized Difference Vegetation Index (NDVI)==.
> 2.  Create a "difference image" by subtracting the more recent NDVI image from the older one.
> 3.  Apply a threshold to the difference image to create a binary mask, highlighting areas of significant vegetation loss.
> 4.  What does a high positive value in the difference image signify?
>
> > [!TIP] Hint
> > The formula for NDVI is `(NIR - Red) / (NIR + Red)`. For Landsat 8, this corresponds to ==Band 5 (NIR)== and ==Band 4 (Red)==. Ensure your data is in a floating-point format for the division.

---

> [!question]
> ### Exercise 4: Preparing Multispectral Data for a CNN
> A Convolutional Neural Network (CNN) for land cover classification requires input data to be standardized. You have a 6-band multispectral image (Blue, Green, Red, NIR, SWIR1, SWIR2).
>
> 1.  Load the 6-band image and stack the bands into a single array with shape `(height, width, channels)`.
> 2.  For each band (channel), calculate its mean and standard deviation.
> 3.  Apply ==z-score normalization== to each band independently using the formula: `(pixel_value - mean) / std_dev`.
> 4.  Verify that the mean of the resulting normalized bands is approximately 0 and the standard deviation is approximately 1.
>
> > [!TIP] Hint
> > Normalizing each band independently prevents bands with larger value ranges (like NIR) from disproportionately influencing the model's training process.

---

> [!question]
> ### Exercise 5: Flood Mapping with SAR Change Detection
> You are tasked with mapping a flood event using two Sentinel-1 SAR images: one pre-flood and one during-flood.
>
> 1.  Ensure both SAR images are ==co-registered== (perfectly aligned).
> 2.  Apply a speckle filter to both images to improve signal quality.
> 3.  Create a log-ratio change image using the formula: `log(Intensity_post) - log(Intensity_pre)`.
> 4.  Analyze the resulting image. Smooth surfaces like floodwater typically have very low backscatter. How would you expect flooded areas to appear in the log-ratio image?
>
> > [!TIP] Hint
> > Water appears dark in SAR imagery due to specular reflection. A decrease in backscatter from pre-flood (e.g., fields, vegetation) to during-flood (water) will result in a strong negative value in the log-ratio image.

---

> [!question]
> ### Exercise 6: Data Fusion by Stacking Optical and SAR Data
> To improve a land cover classification model, you decide to fuse optical and SAR data. You have a 4-band Sentinel-2 image (Red, Green, Blue, NIR) and a co-registered Sentinel-1 SAR intensity image of the same area.
>
> 1.  Load both the multispectral and SAR images.
> 2.  Resample one of the images so that both have the ==same spatial resolution== and dimensions.
> 3.  Stack the SAR band with the 4 multispectral bands to create a new ==5-channel data cube==.
> 4.  Explain one potential advantage of this fused dataset for a deep learning model compared to using only the optical data.
>
> > [!TIP] Hint
> > The order of the final channels matters. A common convention is to place the optical bands first, followed by the SAR bands. SAR provides structural information (e.g., texture, roughness) that is complementary to the spectral information from optical sensors.

---

> [!question]
> ### Exercise 7: Interpreting SAR Backscatter for Ship Detection
> You are analyzing a Sentinel-1 SAR image over a busy shipping lane. Your goal is to understand the SAR signatures of ships to inform the design of a ship detection model.
>
> 1.  Load the SAR image.
> 2.  Identify at least three potential ships in the image.
> 3.  Describe their appearance. Pay attention to the ==high backscatter== from the ship's metal structure and the ==dark, calm wake== trailing behind it.
> 4.  Explain why a ship appears as a bright object against the darker sea surface.
>
> > [!TIP] Hint
> > Ships, with their complex metal superstructures, cause strong ==dihedral and trihedral corner reflections==, sending a large amount of the radar signal back to the sensor. The surrounding sea surface, in contrast, scatters the signal away.

---

> [!question]
> ### Exercise 8: Burn Scar Analysis using dNBR
> A wildfire has occurred in a national park. You are provided with pre-fire and post-fire Landsat 8 images. Your task is to delineate the burn scar using the ==Differenced Normalized Burn Ratio (dNBR)==.
>
> 1.  For both images, calculate the Normalized Burn Ratio (NBR) using the formula: `(NIR - SWIR2) / (NIR + SWIR2)`.
> 2.  Calculate the dNBR: `dNBR = NBR_prefire - NBR_postfire`.
> 3.  Apply a color map to the dNBR result to visualize burn severity. High dNBR values indicate more severe burning.
>
> > [!TIP] Hint
> > For Landsat 8, the required bands are ==Band 5 (NIR)== and ==Band 7 (SWIR2)==. The dNBR is a robust index for quantifying fire impact on an ecosystem.

---

> [!question]
> ### Exercise 9: Creating Image Patches for a Deep Learning Model
> Deep learning models are typically trained on smaller image patches, not entire satellite scenes. You have a large, fused 5-channel image (from Exercise 6) and a corresponding ground truth mask for land cover.
>
> 1.  Define a patch size, for example, `==128x128 pixels==`.
> 2.  Write a script that extracts non-overlapping (or overlapping with a defined stride) patches from both the 5-channel image and the ground truth mask.
> 3.  Store these patches as `(image_patch, mask_patch)` pairs.
> 4.  Explain why using patches is more memory-efficient and helps in ==data augmentation==.
>
> > [!TIP] Hint
> > Creating patches effectively increases the size of your training dataset. If you use an overlapping stride (e.g., 64 pixels), you generate even more training samples from the same source image.

---

> [!question]
> ### Exercise 10: Pan-Sharpening for Enhanced Visual Interpretation
> You have a multispectral image with 30m resolution and a co-registered panchromatic (PAN) image of the same area with 15m resolution. Your goal is to create a high-resolution color image.
>
> 1.  Upsample the low-resolution multispectral image to match the 15m resolution of the PAN image. Use an interpolation method like ==bicubic interpolation==.
> 2.  Convert the upsampled multispectral image to a different color space, such as HSV (Hue, Saturation, Value).
> 3.  Replace the 'Value' (or 'Intensity') channel with the high-resolution panchromatic band.
> 4.  Convert the modified HSV image back to the RGB color space. Compare the original and the ==pan-sharpened== image.
>
> > [!TIP] Hint
> > This technique, a form of data fusion, leverages the high spatial resolution of the panchromatic band to sharpen the coarser spectral information of the multispectral bands, resulting in a visually detailed color image.